<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
-->

<!-- Put site-specific property overrides in this file. -->

<configuration>

	<!--NN HA related configuration **Begin** -->
	<property>
		<name>dfs.nameservices</name>
		<value>kgdc</value>
		<final>true</final>
		<description>
			Comma-separated list of nameservices.
			as same as fs.defaultFS in core-site.xml.	
		</description>
	</property>
	
	<property>
		<name>dfs.ha.namenodes.kgdc</name>
		<value>hd21,hd22</value>
		<final>true</final>
	</property>

	<property>
		<name>dfs.namenode.rpc-address.kgdc.hd21</name>
		<value>10.1.80.191:8020</value>
	</property>

	<property>
		<name>dfs.namenode.rpc-address.kgdc.hd22</name>
		<value>10.1.80.192:8020</value>
	</property>

	<property>
		<name>dfs.namenode.http-address.kgdc.hd21</name>
		<value>10.1.80.191:50070</value>
	</property>

	<property>
		<name>dfs.namenode.http-address.kgdc.hd22</name>
		<value>10.1.80.192:50070</value>
	</property>

	<property>
		<name>dfs.namenode.servicerpc-address.kgdc.hd21</name>
		<value>10.1.80.191:53310</value>
	</property>

	<property>
		<name>dfs.namenode.servicerpc-address.kgdc.hd22</name>
		<value>10.1.80.192:53310</value>
	</property>

	<property>
		<name>dfs.ha.automatic-failover.enabled</name>
		<value>true</value>
	</property>

	<property>
		<name>dfs.client.failover.proxy.provider.kgdc</name>
		<value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
	</property>

	<property>
		<name>dfs.ha.fencing.methods</name>
		<value>sshfence(storm:32200)</value>
		<final>true</final>
	</property>

	<property>
		<name>dfs.ha.fencing.ssh.private-key-files</name>
		<value>/home/storm/.ssh/id_rsa</value>
		<final>true</final>
	</property>

	<property>
		<name>dfs.ha.fencing.ssh.connect-timeout</name>
		<value>1000</value>
	</property>

	<property>
		<name>dfs.journalnode.edits.dir</name>
		<value>/data1/hadoop/hd_space/tmp/journal</value>
	</property>

	<property>
		<name>dfs.namenode.shared.edits.dir</name>
		<value>qjournal://hd23:8485;hd24:8485;hd25:8485/kgdc</value>
		<final>true</final>
	</property>

	<!-- NN HA related configuration **end** -->

	<!-- NameNode related configuration **Begin** -->
	<property>
		<name>dfs.namenode.name.dir</name>
		<value>/data1/hadoop/hd_space/dfs/name</value>
	</property>

	<property>
		<name>dfs.blocksize</name>
		<value>268435456</value>
		<final>true</final>	
	</property>

	<property>
		<name>dfs.namenode.handler.count</name>
		<value>30</value>
		<description>
		More NameNode server threads to handle RPCs from large number of DataNodes.
		</description>
	</property>

	<!-- NameNode related configuration **end** -->
	
	<!-- DataNode related configuration **Begin**-->

	<property>
		<name>dfs.replication</name>
		<value>2</value>
	</property>

	<property>
		<name>dfs.webhdfs.enabled</name>
		<value>true</value>
	</property>
	
	<property>
		<name>dfs.permissions</name>
		<value>false</value>
	</property>

	<property>
		<name>dfs.permissions.enabled</name>
		<value>false</value>
	</property>

	<property>
		<name>dfs.datanode.failed.volumes.tolerated</name>
		<value>0</value>
		<description>
		能够导致DN挂掉的坏硬盘最大数，默认0就是只要有1个硬盘坏了，DN就会shutdown。能够导致DN挂掉的坏硬盘最大数，默认0就是只要有1个硬盘坏了，DN就会shutdown。
		</description>
	</property>

	<property>
		<name>dfs.datanode.du.reserved</name>
		<value>107374182400</value>
		<description>
		每块磁盘所保留的空间大小，需要设置一些，主要是给非hdfs文件使用，默认是不保留，0字节。此处配置10GB=1024*1024*1024*10
		</description>
	</property>	
	
	<property>
		<name>dfs.datanode.balance.bandwidthPerSec</name>
		<value>31457280</value>
		<description>
		HDFS平衡器检测集群中使用过度或者使用不足的DataNode，并在这些DataNode之间移动数据块来保证负载均衡。如果不对平衡操作进行带宽限制，那么它会很快就会抢占所有的网络资源，不会为Mapreduce作业或者数据输入预留资源。30M
		</description>
	</property>

	<property>
		<name>dfs.datanode.handler.count</name>
		<value>10</value>
		<description>DN 的服务连接处理线程数</description>
	</property>

	<property>
		<name>dfs.support.append</name>
		<value>true</value>
		<description>支持文件append</description>
	</property>

	<property>
		<name>dfs.datanode.max.xcievers</name>
		<value>100000</value>
	</property>

        <property>
                 <name>dfs.datanode.fsdataset.volume.choosing.policy</name>
                 <value>org.apache.hadoop.hdfs.server.datanode.fsdataset.AvailableSpaceVolumeChoosingPolicy</value>
                 <description>
                  datanode数据副本存放的磁盘选择策略,有2种方式一种是轮询方式（org.apache.hadoop.hdfs.server.datanode.fsdataset.RoundRobinVolumeChoosingPolicy，为默认方式），
                  另一种为选择可用空间足够多的磁盘存储方式,这个为了防止各个节点上的各个磁盘的存储均匀采用这个方式。
                 </description>
       </property>
        <property>
                  <name>dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold</name>
                  <value>10737418240</value>
                  <description>
                   当在上面datanode数据副本存放的磁盘选择可用空间足够多的磁盘存储方式开启时，此选项才生效。这个参数主要功能是：
                   首先计算出两个值，算出一个节点上所有磁盘中具有最大可用空间，另外一个值是所有磁盘中最小可用空间，如果这
                   两个值相差小于该配置项指定的阀值时，则就用轮询方式的磁盘选择策略选择磁盘存储数据副本,如果比这个阀值大的话则
                   还是选择可用空间足够多的磁盘存储方式。此项默认值为10737418240即10G
                  </description>
        </property>
        <property>
                  <name>dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction</name>
                  <value>0.75f</value>
                  <description>
                   默认值是0.75f，一般使用默认值就行。具体解析：有多少比例的数据副本应该存储到剩余空间足够多的磁盘上。
                   该配置项取值范围是0.0-1.0，一般取0.5-1.0，如果配置太小，会导致剩余空间足够的磁盘实际上没分配足够的数据副本,
                   而剩余空间不足的磁盘取需要存储更多的数据副本，导致磁盘数据存储不均衡。
                  </description>
       </property>

       <property>
           <name>dfs.client.read.shortcircuit</name>
           <value>false</value>
           <description>配置dfsClient可以通过绕过datanode直接获取相关文件信息</description>
       </property>
        <property>
                     <name>dfs.domain.socket.path</name>
                     <value>/var/lib/hadoop-hdfs/dn_socket</value>
                      <description>Datanode和DFSClient之间沟通的Socket的本地路径</description>
                      </property>
        <property>
              <name>dfs.datanode.data.dir</name>
              <value>file:/data1/hadoop/hd_space/dfs/data,file:/data2/hadoop/hd_space/dfs/data</value>
      </property>
       
       
	<!--DataNode related configuration **end**-->
</configuration>
